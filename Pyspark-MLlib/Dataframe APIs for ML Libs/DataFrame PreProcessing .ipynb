{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics Covered in DataFarame PreProcessing with PySpark\n",
    "\n",
    "* 1.Converting String in to Float\n",
    "* 2.Checking Missing Values \n",
    "* 3.Treating Missing Values \n",
    "* 4.Statistics\n",
    "* 5.checking correlation using pearson method\n",
    "* 6.VectorAssembler\n",
    "* 7.Standard Scaling\n",
    "* 8.PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.mllib.feature import StandardScaler,PCA\n",
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DataFrame_Preprocessing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.read.csv(\"Admission_Prediction.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|GRE Score|TOEFL Score|University Rating|SOP|LOR |CGPA|Research|Chance of Admit |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|337      |118        |4                |4.5|4.5 |9.65|1       |0.92            |\n",
      "|324      |107        |4                |4.0|4.5 |8.87|1       |0.76            |\n",
      "|316      |104        |3                |3.0|3.5 |8.0 |1       |0.72            |\n",
      "|322      |110        |3                |3.5|2.5 |8.67|1       |0.8             |\n",
      "|null     |103        |2                |2.0|3.0 |8.21|0       |0.65            |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GRE Score: string (nullable = true)\n",
      " |-- TOEFL Score: string (nullable = true)\n",
      " |-- University Rating: string (nullable = true)\n",
      " |-- SOP: double (nullable = true)\n",
      " |-- LOR : double (nullable = true)\n",
      " |-- CGPA: double (nullable = true)\n",
      " |-- Research: integer (nullable = true)\n",
      " |-- Chance of Admit : double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting String in to Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "new_data = dataset.select(*(col(c).cast(\"float\") for c in dataset.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|GRE Score|TOEFL Score|University Rating|SOP|LOR |CGPA|Research|Chance of Admit |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|337.0    |118.0      |4.0              |4.5|4.5 |9.65|1.0     |0.92            |\n",
      "|324.0    |107.0      |4.0              |4.0|4.5 |8.87|1.0     |0.76            |\n",
      "|316.0    |104.0      |3.0              |3.0|3.5 |8.0 |1.0     |0.72            |\n",
      "|322.0    |110.0      |3.0              |3.5|2.5 |8.67|1.0     |0.8             |\n",
      "|null     |103.0      |2.0              |2.0|3.0 |8.21|0.0     |0.65            |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GRE Score: float (nullable = true)\n",
      " |-- TOEFL Score: float (nullable = true)\n",
      " |-- University Rating: float (nullable = true)\n",
      " |-- SOP: float (nullable = true)\n",
      " |-- LOR : float (nullable = true)\n",
      " |-- CGPA: float (nullable = true)\n",
      " |-- Research: float (nullable = true)\n",
      " |-- Chance of Admit : float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### when we drop the columns is where null values are there inside the dataframe\n",
    "# data_without_missing = dataset.dropna(how='any')\n",
    "# data_without_missing = dataset.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|GRE Score|TOEFL Score|University Rating|SOP|LOR |CGPA|Research|Chance of Admit |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|        5|          3|                1|  0|   0|   0|       0|               0|\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, isnan, when\n",
    "#checking for null ir nan type values in our columns\n",
    "new_data.select([count(when(col(c).isNull(), c)).alias(c) for c in new_data.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating Missing Values with Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "imputer = Imputer(inputCols=[\"GRE Score\", \"TOEFL Score\",\"University Rating\"], \n",
    "                  outputCols=[\"GRE Score\", \"TOEFL Score\",\"University Rating\"])\n",
    "model = imputer.fit(new_data)\n",
    "\n",
    "imputed_data = model.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|GRE Score|TOEFL Score|University Rating|SOP|LOR |CGPA|Research|Chance of Admit |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|337.0    |118.0      |4.0              |4.5|4.5 |9.65|1.0     |0.92            |\n",
      "|324.0    |107.0      |4.0              |4.0|4.5 |8.87|1.0     |0.76            |\n",
      "|316.0    |104.0      |3.0              |3.0|3.5 |8.0 |1.0     |0.72            |\n",
      "|322.0    |110.0      |3.0              |3.5|2.5 |8.67|1.0     |0.8             |\n",
      "|316.4909 |103.0      |2.0              |2.0|3.0 |8.21|0.0     |0.65            |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputed_data.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|GRE Score|TOEFL Score|University Rating|SOP|LOR |CGPA|Research|Chance of Admit |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|        0|          0|                0|  0|   0|   0|       0|               0|\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, isnan, when\n",
    "#checking for null or nan type values in our columns\n",
    "imputed_data.select([count(when(col(c).isNull(), c)).alias(c) for c in imputed_data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4064577967296779"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data.corr('SOP','Research')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = imputed_data.drop('Chance of Admit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we need to convert dataframe into a RDD to check for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = features.columns\n",
    "features_rdd = features.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(340.0, 120.0, 5.0, 4.5, 4.5, 9.90999984741211, 1.0, 0.9700000286102295),\n",
       " (340.0, 120.0, 5.0, 4.5, 4.5, 9.600000381469727, 1.0, 0.9399999976158142),\n",
       " (340.0, 120.0, 4.0, 5.0, 5.0, 9.5, 1.0, 0.9599999785423279),\n",
       " (340.0, 120.0, 4.0, 4.5, 4.0, 9.920000076293945, 1.0, 0.9700000286102295),\n",
       " (340.0, 115.0, 5.0, 5.0, 4.5, 9.0600004196167, 1.0, 0.949999988079071)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## show the top features in rdd\n",
    "features_rdd.top(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_rdd = features.rdd.map(lambda row: row[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(340.0, 120.0, 5.0, 4.5, 4.5, 9.90999984741211, 1.0, 0.9700000286102295),\n",
       " (340.0, 120.0, 5.0, 4.5, 4.5, 9.600000381469727, 1.0, 0.9399999976158142),\n",
       " (340.0, 120.0, 4.0, 5.0, 5.0, 9.5, 1.0, 0.9599999785423279),\n",
       " (340.0, 120.0, 4.0, 4.5, 4.0, 9.920000076293945, 1.0, 0.9700000286102295),\n",
       " (340.0, 115.0, 5.0, 5.0, 4.5, 9.0600004196167, 1.0, 0.949999988079071)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features_rdd.collect()\n",
    "features_rdd.top(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316.49090906 107.20724347   3.11222445   3.373        3.482\n",
      "   8.5775       0.558        0.72174   ]\n",
      "[1.26143706e+02 3.68289658e+01 1.30604295e+00 9.82335671e-01\n",
      " 8.52380762e-01 3.64575080e-01 2.47130261e-01 1.99206139e-02]\n",
      "[500. 500. 500. 500. 500. 500. 279. 500.]\n",
      "[158245.45452881  53603.62173462   1556.11222434   1686.5\n",
      "   1741.           4288.75000238    279.            360.86999956]\n"
     ]
    }
   ],
   "source": [
    "summary = Statistics.colStats(features_rdd)\n",
    "print(summary.mean())  # a dense vector containing the mean value for each column\n",
    "print(summary.variance())  # column-wise variance\n",
    "print(summary.numNonzeros())  # number of nonzeros in each column\n",
    "print(summary.normL1())# return a column of normL1 summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking correlation using pearson method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_mat=Statistics.corr(features_rdd, method=\"pearson\")\n",
    "corr_df = pd.DataFrame(corr_mat)\n",
    "corr_df.index, corr_df.columns = col_names, col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA',\n",
       "       'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA',\n",
       "       'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRE Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819736</td>\n",
       "      <td>0.630379</td>\n",
       "      <td>0.610009</td>\n",
       "      <td>0.515327</td>\n",
       "      <td>0.822921</td>\n",
       "      <td>0.562442</td>\n",
       "      <td>0.807365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL Score</th>\n",
       "      <td>0.819736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646440</td>\n",
       "      <td>0.641482</td>\n",
       "      <td>0.535526</td>\n",
       "      <td>0.808236</td>\n",
       "      <td>0.463112</td>\n",
       "      <td>0.786247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <td>0.630379</td>\n",
       "      <td>0.646440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.726602</td>\n",
       "      <td>0.607916</td>\n",
       "      <td>0.703442</td>\n",
       "      <td>0.425723</td>\n",
       "      <td>0.689575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>0.610009</td>\n",
       "      <td>0.641482</td>\n",
       "      <td>0.726602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665460</td>\n",
       "      <td>0.712155</td>\n",
       "      <td>0.406458</td>\n",
       "      <td>0.684564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>0.515327</td>\n",
       "      <td>0.535526</td>\n",
       "      <td>0.607916</td>\n",
       "      <td>0.665460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636094</td>\n",
       "      <td>0.369054</td>\n",
       "      <td>0.645548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>0.822921</td>\n",
       "      <td>0.808236</td>\n",
       "      <td>0.703442</td>\n",
       "      <td>0.712155</td>\n",
       "      <td>0.636094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497910</td>\n",
       "      <td>0.880543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>0.562442</td>\n",
       "      <td>0.463112</td>\n",
       "      <td>0.425723</td>\n",
       "      <td>0.406458</td>\n",
       "      <td>0.369054</td>\n",
       "      <td>0.497910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.543089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance of Admit</th>\n",
       "      <td>0.807365</td>\n",
       "      <td>0.786247</td>\n",
       "      <td>0.689575</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.645548</td>\n",
       "      <td>0.880543</td>\n",
       "      <td>0.543089</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   GRE Score  TOEFL Score  University Rating       SOP  \\\n",
       "GRE Score           1.000000     0.819736           0.630379  0.610009   \n",
       "TOEFL Score         0.819736     1.000000           0.646440  0.641482   \n",
       "University Rating   0.630379     0.646440           1.000000  0.726602   \n",
       "SOP                 0.610009     0.641482           0.726602  1.000000   \n",
       "LOR                 0.515327     0.535526           0.607916  0.665460   \n",
       "CGPA                0.822921     0.808236           0.703442  0.712155   \n",
       "Research            0.562442     0.463112           0.425723  0.406458   \n",
       "Chance of Admit     0.807365     0.786247           0.689575  0.684564   \n",
       "\n",
       "                       LOR       CGPA  Research  Chance of Admit   \n",
       "GRE Score          0.515327  0.822921  0.562442          0.807365  \n",
       "TOEFL Score        0.535526  0.808236  0.463112          0.786247  \n",
       "University Rating  0.607916  0.703442  0.425723          0.689575  \n",
       "SOP                0.665460  0.712155  0.406458          0.684564  \n",
       "LOR                1.000000  0.636094  0.369054          0.645548  \n",
       "CGPA               0.636094  1.000000  0.497910          0.880543  \n",
       "Research           0.369054  0.497910  1.000000          0.543089  \n",
       "Chance of Admit    0.645548  0.880543  0.543089          1.000000  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|GRE Score|TOEFL Score|University Rating|SOP|LOR |CGPA|Research|Chance of Admit |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|    337.0|      118.0|              4.0|4.5| 4.5|9.65|     1.0|            0.92|\n",
      "|    324.0|      107.0|              4.0|4.0| 4.5|8.87|     1.0|            0.76|\n",
      "|    316.0|      104.0|              3.0|3.0| 3.5| 8.0|     1.0|            0.72|\n",
      "|    322.0|      110.0|              3.0|3.5| 2.5|8.67|     1.0|             0.8|\n",
      "| 316.4909|      103.0|              2.0|2.0| 3.0|8.21|     0.0|            0.65|\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputed_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = imputed_data.drop('Chance of Admit ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=features.columns,outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+----------------+\n",
      "|features                                                    |Chance of Admit |\n",
      "+------------------------------------------------------------+----------------+\n",
      "|[337.0,118.0,4.0,4.5,4.5,9.649999618530273,1.0]             |0.92            |\n",
      "|[324.0,107.0,4.0,4.0,4.5,8.869999885559082,1.0]             |0.76            |\n",
      "|[316.0,104.0,3.0,3.0,3.5,8.0,1.0]                           |0.72            |\n",
      "|[322.0,110.0,3.0,3.5,2.5,8.670000076293945,1.0]             |0.8             |\n",
      "|[316.49090576171875,103.0,2.0,2.0,3.0,8.210000038146973,0.0]|0.65            |\n",
      "+------------------------------------------------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select(\"features\", \"Chance of Admit \").show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = imputed_data.select('Chance of Admit ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|Chance of Admit |\n",
      "+----------------+\n",
      "|            0.92|\n",
      "|            0.76|\n",
      "|            0.72|\n",
      "|             0.8|\n",
      "|            0.65|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = imputed_data.drop('Chance of Admit ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = features.columns\n",
    "features_rdd = features.rdd.map(lambda row: row[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(340.0, 120.0, 5.0, 4.5, 4.5, 9.90999984741211, 1.0),\n",
       " (340.0, 120.0, 5.0, 4.5, 4.5, 9.600000381469727, 1.0),\n",
       " (340.0, 120.0, 4.0, 5.0, 5.0, 9.5, 1.0),\n",
       " (340.0, 120.0, 4.0, 4.5, 4.0, 9.920000076293945, 1.0),\n",
       " (340.0, 115.0, 5.0, 5.0, 4.5, 9.0600004196167, 1.0)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features_rdd.collect()\n",
    "features_rdd.top(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = StandardScaler().fit(features_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features=scaler1.transform(features_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.00524025385319,19.444073123688433,3.5001065242645106,4.540279160253269,4.874114130761268,15.982098619569024,2.011578737704796]\n",
      "[28.847768077888528,17.63149003588697,3.5001065242645106,4.035803698002906,4.874114130761268,14.690281713001964,2.011578737704796]\n",
      "[28.13547750806412,17.1371491937593,2.625079893198383,3.0268527735021795,3.7909776572587637,13.249408705782436,2.011578737704796]\n",
      "[28.669695435432427,18.125830878014643,2.625079893198383,3.5313282357525426,2.70784118375626,14.359046811247923,2.011578737704796]\n",
      "[28.179185951157212,16.972368913050072,1.7500532621322553,2.017901849001453,3.249409420507512,13.59720574748733,0.0]\n"
     ]
    }
   ],
   "source": [
    "for data in scaled_features.take(5):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=3)\n",
    "model = pca.fit(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DenseVector([-31.9772, 8.0295, -18.9905]),\n",
       " DenseVector([-30.0457, 7.6391, -17.5162]),\n",
       " DenseVector([-27.8526, 8.392, -17.4271]),\n",
       " DenseVector([-28.7505, 8.9783, -18.7505]),\n",
       " DenseVector([-26.4578, 7.7233, -19.1492])]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store dense vector in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =result.map(lambda x: (x, )).toDF([\"PCA_Features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------+\n",
      "|PCA_Features                                               |\n",
      "+-----------------------------------------------------------+\n",
      "|[-31.977182487884036,8.029514763493243,-18.990453304678162]|\n",
      "|[-30.045686880290237,7.639077844922069,-17.51623616623448] |\n",
      "|[-27.852638239765152,8.392009538098923,-17.427074491217123]|\n",
      "|[-28.75051513242634,8.978264691544112,-18.750488476990267] |\n",
      "|[-26.457821418000282,7.723327004504269,-19.149180690578625]|\n",
      "|[-31.083831050782454,8.278073275989826,-19.080459919848717]|\n",
      "|[-28.68952685554881,8.384321835447519,-17.797432187149532] |\n",
      "|[-26.569596508855597,6.63946310855808,-17.944097192101765] |\n",
      "|[-24.82613160888541,8.256382319020885,-19.349665442263994] |\n",
      "|[-28.21294041814849,7.258105092116565,-19.562480895131383] |\n",
      "|[-28.96909729084087,8.260368281698211,-17.693333297572856] |\n",
      "|[-30.50808885154048,7.796030288412726,-17.966541505750584] |\n",
      "|[-30.679796347128107,7.843434871719907,-18.113950167927552]|\n",
      "|[-28.061111225041095,8.148375853385518,-17.60159778694419] |\n",
      "|[-27.443911746514434,8.806512394929458,-18.006387726361968]|\n",
      "|[-27.294809634762846,7.199613494166247,-19.177076375587625]|\n",
      "|[-28.19613637008013,6.914939863847723,-19.253041669191095] |\n",
      "|[-28.2933443706931,8.396699131556772,-17.75467621750696]   |\n",
      "|[-28.499864856244326,7.000838760264483,-19.552122727995897]|\n",
      "|[-27.029928112884416,6.629862208629025,-18.433295117669324]|\n",
      "+-----------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
